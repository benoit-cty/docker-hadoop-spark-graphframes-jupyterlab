{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pySpark : Streaming Tweet (modern Structured Streaming version)\n",
    "\n",
    "https://medium.com/@ch.nabarun/easy-to-play-with-twitter-data-using-spark-structured-streaming-76fe86f1f81c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- streaming is running -------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, split\n",
    "\n",
    "# create Spark session\n",
    "spark = SparkSession.builder.appName(\"TwitterDataFrame\").getOrCreate()\n",
    "\n",
    "# read the tweet data from socket\n",
    "tweet_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9009) \\\n",
    "    .load()\n",
    "\n",
    "# type cast the column value\n",
    "tweet_df_string = tweet_df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "\n",
    "# split words based on space, filter out hashtag values and group them up\n",
    "tweets_tab = tweet_df_string.withColumn('word', explode(split(col('value'), ' '))) \\\n",
    "    .groupBy('word') \\\n",
    "    .count() \\\n",
    "    .sort('count', ascending=False). \\\n",
    "    filter(col('word').contains('#'))\n",
    "\n",
    "# write the above data into memory. consider the entire analysis in all iteration (output mode = complete). and let the trigger runs in every 2 secs.\n",
    "writeTweet = tweets_tab.writeStream. \\\n",
    "    outputMode(\"complete\"). \\\n",
    "    format(\"memory\"). \\\n",
    "    queryName(\"tweetquery\"). \\\n",
    "    trigger(processingTime='2 seconds'). \\\n",
    "    start()\n",
    "\n",
    "print(\"----- streaming is running -------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM tweetquery LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "----------- 2020-11-25 21:40:18 -----------\n",
    "+--------------------+-------------+\n",
    "|             hashtag|hashtag_count|\n",
    "+--------------------+-------------+\n",
    "|            #COVID19|            4|\n",
    "|         #earthquake|            3|\n",
    "|        #FlynnPardon|            3|\n",
    "|         #LifeGoesOn|            2|\n",
    "|   #Thanksgiving2020|            2|\n",
    "|              #Labor|            2|\n",
    "|       #WITHAPURPOSE|            2|\n",
    "|                   #|            2|\n",
    "|#OhTheWeatherOuts...|            2|\n",
    "|             #pdx911|            2|\n",
    "+--------------------+-------------+\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
