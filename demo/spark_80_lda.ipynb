{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation\n",
    "\n",
    "TF-IDF : https://www.seoquantum.com/billet/optimisez-vos-contenus-mots-rares\n",
    "\n",
    "LDA :\n",
    "https://fr.wikipedia.org/wiki/Allocation_de_Dirichlet_latente\n",
    "\n",
    "\n",
    "\n",
    "http://eric.univ-lyon2.fr/~ricco/cours/slides/TM.D%20-%20reduction%20de%20dimension.pdf (Ã  partir de la page 22)\n",
    "\n",
    "Dataset : https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews\n",
    "\n",
    "This is an updated version to Spark 3 of the 1.6 version of https://medium.com/@connectwithghosh/topic-modelling-with-latent-dirichlet-allocation-lda-in-pyspark-2cb3ebd5678e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mv ../data/lda/'Womens Clothing E-Commerce Reviews.csv' ../data/lda'WomensClothingE-CommerceReviews.csv'\n",
    "# !ls ../data/\n",
    "# !mv ../data/ldaWomensClothingE-CommerceReviews.csv ../data/lda/\n",
    "# !hdfs dfs -mkdir -p /demo/lda/\n",
    "# !hdfs dfs -copyFromLocal -f ../data/lda/* /demo/lda/\n",
    "# !hdfs dfs -ls /demo/lda/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('LDA') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing some librariesimport pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "# stuff we'll need for text processing\n",
    "from nltk.corpus import stopwords\n",
    "import re as re\n",
    "from pyspark.ml.feature import CountVectorizer , IDF # stuff we'll need for building the model\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sqlContext.read.format(\"csv\") \\\n",
    "   .options(header='true', inferschema='true') \\\n",
    "   .load(\"/demo/lda/ldaWomensClothingE-CommerceReviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+---+-----+--------------------+------+---------------+-----------------------+-------------+---------------+----------+\n",
      "|_c0|Clothing ID|Age|Title|         Review Text|Rating|Recommended IND|Positive Feedback Count|Division Name|Department Name|Class Name|\n",
      "+---+-----------+---+-----+--------------------+------+---------------+-----------------------+-------------+---------------+----------+\n",
      "|  0|        767| 33| null|Absolutely wonder...|     4|              1|                      0|    Initmates|       Intimate| Intimates|\n",
      "|  1|       1080| 34| null|\"Love this dress!...|     5|              1|                      4|      General|        Dresses|   Dresses|\n",
      "+---+-----------+---+-----+--------------------+------+---------------+-----------------------+-------------+---------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data.rdd.map(lambda x : x['Review Text']).filter(lambda x: x is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absolutely wonderful - silky and sexy and comfortable',\n",
       " '\"Love this dress!  it\\'s sooo pretty.  i happened to find it in a store, and i\\'m glad i did bc i never would have ordered it online bc it\\'s petite.  i bought a petite and am 5\\'8\"\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.\"']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StopWords[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = reviews                                                \\\n",
    "    .map( lambda document: document.strip().lower())               \\\n",
    "    .map( lambda document: re.split(\" \", document))          \\\n",
    "    .map( lambda word: [x for x in word if x.isalpha()])           \\\n",
    "    .map( lambda word: [x for x in word if len(x) > 3] )           \\\n",
    "    .map( lambda word: [x for x in word if x not in StopWords])    \\\n",
    "    .zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable'], 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txts = sqlContext.createDataFrame(tokens, [\"list_of_words\",'index'])# TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|       list_of_words|index|\n",
      "+--------------------+-----+\n",
      "|[absolutely, wond...|    0|\n",
      "|[sooo, happened, ...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_txts.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"list_of_words\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
    "cvmodel = cv.fit(df_txts)\n",
    "result_cv = cvmodel.transform(df_txts)# IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|       list_of_words|index|        raw_features|\n",
      "+--------------------+-----+--------------------+\n",
      "|[absolutely, wond...|    0|(2421,[40,100,374...|\n",
      "|[sooo, happened, ...|    1|(2421,[0,6,8,10,1...|\n",
      "|[high, hopes, dre...|    2|(2421,[1,7,8,14,2...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wonderful'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cv.show(3)\n",
    "cvmodel.vocabulary[40]\n",
    "cvmodel.vocabulary[100]\n",
    "cvmodel.vocabulary[374]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[raw_features: vector]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cv[['raw_features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|       list_of_words|index|        raw_features|            features|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|[absolutely, wond...|    0|(2421,[40,100,374...|(2421,[40,100,374...|\n",
      "|[sooo, happened, ...|    1|(2421,[0,6,8,10,1...|(2421,[0,6,8,10,1...|\n",
      "|[high, hopes, dre...|    2|(2421,[1,7,8,14,2...|(2421,[1,7,8,14,2...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_tfidf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(list_of_words=['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable'], index=0, raw_features=SparseVector(2421, {40: 1.0, 100: 1.0, 374: 1.0, 554: 1.0, 641: 1.0}), features=SparseVector(2421, {40: 2.8147, 100: 3.4858, 374: 4.9002, 554: 5.353, 641: 5.5826}))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tfidf.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = result_tfidf[['index','features']].rdd.map(list)\n",
    "# dataset.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|index|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(2421,[40,100,374...|\n",
      "|    1|(2421,[0,6,8,10,1...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = result_tfidf[['index','features']]\n",
    "dataset.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "max_iterations = 100\n",
    "lda = LDA(k=num_topics, maxIter=max_iterations)\n",
    "lda_model = lda.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|  [3, 1, 155, 14, 6]|[0.01537205140417...|\n",
      "|    1| [57, 5, 0, 196, 71]|[0.01578505275315...|\n",
      "|    2|  [1, 2, 132, 9, 11]|[0.01114037985121...|\n",
      "|    3|    [3, 1, 0, 5, 41]|[0.01215684394674...|\n",
      "|    4|[55, 266, 4, 280, 5]|[0.01006032501593...|\n",
      "|    5|    [8, 6, 2, 3, 73]|[0.01022646024831...|\n",
      "|    6| [37, 221, 1, 0, 34]|[0.01273654923773...|\n",
      "|    7|[187, 282, 202, 9...|[0.01388437475495...|\n",
      "|    8|[75, 26, 341, 294...|[0.03827748471183...|\n",
      "|    9|[228, 243, 13, 24...|[0.01004399154315...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordNumbers = 5\n",
    "topics = lda_model.describeTopics(maxTermsPerTopic = wordNumbers)\n",
    "topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 size dress chest small would \n",
      "1 jeans great love leggings many \n",
      "2 dress like arms fabric look \n",
      "3 size dress love great runs \n",
      "4 black cami wear spring great \n",
      "5 ordered would like size thought \n",
      "6 long highly dress love length \n",
      "7 favorite purchase denim pair never \n",
      "8 general petite suit today sweater \n",
      "9 washed wash bought lightweight wear \n"
     ]
    }
   ],
   "source": [
    "wordNumbers = 5\n",
    "\n",
    "def topic_render(topic, words):\n",
    "    out=''\n",
    "    for i in words:\n",
    "        out += cvmodel.vocabulary[i] + ' '\n",
    "    print(topic, out)\n",
    "\n",
    "for row in topics.collect():\n",
    "    topic_render(row[0], row[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
